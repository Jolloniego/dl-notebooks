{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Clase6 - CNNs_2_Solucion.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9kM-aVQsV0Ie"},"source":["# Imports globales y funciones de utilidad"]},{"cell_type":"code","metadata":{"id":"NpqMPo4nV4UB"},"source":["import time\n","import torch\n","import itertools\n","import torchvision\n","import numpy as np\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from torchvision import transforms\n","from torchvision.datasets import CIFAR10\n","from torch.utils.data.dataloader import DataLoader\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YGyynDexV60_"},"source":["def get_dataloaders(train_transf, test_transf, batch_size):\n","\n","  train_dataset = CIFAR10(\"data\", train=True, download=True, transform=train_transf)\n","  test_dataset = CIFAR10(\"data\", train=False, download=True, transform=test_transf)\n","\n","  train_size = int(0.8 * len(train_dataset))\n","  valid_size = len(train_dataset) - train_size\n","  train_dataset, validation_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n","\n","  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n","  valid_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n","  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n","\n","  return train_loader, valid_loader, test_loader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7hZyH1P8Velv"},"source":["# Image Augmentation\n","\n","La primera parte de este laboratorio consiste en expandir un poco el modelo de LeNet para tener más parámetros y luego explorar algunas técnicas de Image Augmentation.\n","\n","El modelo a implementar es el siguiente:\n","\n","\n","![Image](https://i.ibb.co/WxGgbmL/Capture.png)\n"]},{"cell_type":"code","metadata":{"id":"chgl8-GKTyfV"},"source":["class CustomCNN(nn.Module):\n","  def __init__(self, in_channels):\n","    # in_channels: int, cantidad de canales de la imagen original\n","    super(CustomCNN, self).__init__()\n","    # Su implementacion\n","    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, stride=1, padding=1)\n","    self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n","    self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n","    self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n","    self.conv5 = nn.Conv2d(in_channels=64, out_channels=120, kernel_size=3, stride=1, padding=1)\n","    self.fc1 = nn.Linear(in_features=4*4*120, out_features=512)\n","    self.output = nn.Linear(in_features=512, out_features=10)\n","    self.dropout = nn.Dropout(p=0.5)\n","\n","\n","  def forward(self, x):\n","    result = F.relu(self.conv1(x))\n","    result = F.relu(self.conv2(result))\n","    result = self.pooling(result)\n","    \n","    result = F.relu(self.conv3(result))\n","    result = F.relu(self.conv4(result))\n","    result = self.pooling(result)\n","\n","    result = F.relu(self.conv5(result))\n","    result = self.pooling(result)\n","    \n","    result = result.flatten(1)\n","    result = self.dropout(result)\n","\n","    result = F.relu(self.fc1(result))\n","    result = self.dropout(result)\n","\n","    result = self.output(result)\n","\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGisRfZ8bYXW"},"source":["## Funciones genericas para entrenar nuestros modelos\n","\n","Vamos a utilizar las mismas funciones que implementamos en los laboratorios anteriores para entrenar y testear nuestros modelos."]},{"cell_type":"code","metadata":{"id":"6Gp496cWTyh-"},"source":["def train_epoch(training_model, loader, criterion, optim):\n","    training_model.train()\n","    epoch_loss = 0.0\n","    all_labels = []\n","    all_predictions = []\n","    \n","    for images, labels in loader:\n","      all_labels.extend(labels.numpy())  \n","\n","      optim.zero_grad()\n","\n","      predictions = training_model(images.to(device))\n","      all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n","\n","      loss = criterion(predictions, labels.to(device))\n","      \n","      loss.backward()\n","      optim.step()\n","\n","      epoch_loss += loss.item()\n","\n","    return epoch_loss / len(loader), accuracy_score(all_labels, all_predictions) * 100\n","\n","\n","def validation_epoch(val_model, loader, criterion):\n","    val_model.eval()\n","    epoch_loss = 0.0\n","    all_labels = []\n","    all_predictions = []\n","    \n","    with torch.no_grad():\n","      for images, labels in loader:\n","        all_labels.extend(labels.numpy())  \n","\n","        predictions = val_model(images.to(device))\n","        all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n","\n","        loss = criterion(predictions, labels.to(device))\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(loader), accuracy_score(all_labels, all_predictions) * 100\n","  \n","\n","def train_model(model, train_loader, test_loader, criterion, optim, number_epochs):\n","  train_history = []\n","  test_history = []\n","  accuracy_history = []\n","\n","  for epoch in range(number_epochs):\n","      start_time = time.time()\n","\n","      train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n","      train_history.append(train_loss)\n","      print(\"Training epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n","            .format(epoch + 1, train_loss, train_acc, time.time() - start_time))\n","\n","      start_time = time.time()\n","      test_loss, acc = validation_epoch(model, test_loader, criterion)\n","      test_history.append(test_loss)\n","      accuracy_history.append(acc)\n","      print(\"Validation epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n","            .format(epoch + 1, test_loss, acc, time.time() - start_time))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IrGeplg5bmKm"},"source":["## Entrenando modelos \n","\n","Comenzamos definiendo una seccion de código con valores por defecto de hiperparámetros que vamos a utilizar y luego entrenamos un modelo de la CNN definida anteriormente sin usar augmentation en los datos y otro haciendo uso del mismo.\n"]},{"cell_type":"code","metadata":{"id":"rj_T5Fza6efw"},"source":["# Global models config\n","\n","BATCH_SIZE = 32\n","LR = 0.001\n","NUMBER_EPOCHS = 10\n","criterion = nn.CrossEntropyLoss().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"137kQNukTyoI"},"source":["# Fijamos las semillas siempre para poder comparar.\n","\n","torch.manual_seed(42)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Creamos los dataloaders\n","test_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","train_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","train_loader, valid_loader, test_loader = get_dataloaders(train_transform, test_transform, BATCH_SIZE)\n","\n","# Definimos el modelo y el optimizador\n","modelo_sin_aug = CustomCNN(3).to(device)\n","optimizer = torch.optim.Adam(modelo_sin_aug.parameters(), lr=LR)\n","\n","# Entrenamos\n","train_model(modelo_sin_aug, train_loader, valid_loader, criterion, optimizer, NUMBER_EPOCHS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_c-x46dYUyk"},"source":["torch.manual_seed(42)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Creamos los datasets\n","test_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","# Definir transormaciones que vamos a aplicar al set de entrenamiento\n","train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor()\n","])\n","train_loader, valid_loader, test_loader = get_dataloaders(train_transform, test_transform, BATCH_SIZE)\n","\n","\n","# Crear el modelo, optimizador y entrenarlo\n","modelo_con_aug = CustomCNN(3).to(device)\n","optimizer = torch.optim.Adam(modelo_con_aug.parameters(), lr=LR)\n","\n","train_model(modelo_con_aug, train_loader, valid_loader, criterion, optimizer, NUMBER_EPOCHS)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pduauAlXcqZt"},"source":["## Evaluando los modelos en los datos de test\n","\n","Vamos a comenzar evaluando en los datos de test normales y luego vamos a aplicar distintas transformaciones (para simular entornos más reales de datos) y vamos a ver la performance y robustez de los modelos que entrenamos anteriormente.\n","\n","Primero agregar horizontal flip obligatorio(p=1) y luego vertical flip obligatorio, qué pasa con los modelos?"]},{"cell_type":"code","metadata":{"id":"tNp0-FmEFH16","executionInfo":{"status":"ok","timestamp":1601510298534,"user_tz":180,"elapsed":3136,"user":{"displayName":"Juan Olloniego","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFZMy1xYdrq8EuW2y-CLv6Eae8Tfe4Qp-uZpYfQQ=s64","userId":"13959738928832749591"}},"outputId":"e1c75981-1f83-4b83-e536-be47c01afecc","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["test_transform = transforms.Compose([\n","  transforms.ToTensor()                              \n","])\n","\n","_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n","\n","test_loss, accuracy = validation_epoch(modelo_sin_aug, test_loader, criterion)\n","print(f\"Modelo entrenado sin augmentation: Test set: {test_loss:.6f} Loss. Accuracy {accuracy:.2f}%\")\n","\n","test_loss, accuracy = validation_epoch(modelo_con_aug, test_loader, criterion)\n","print(f\"Modelo entrenado con augmentation: Test set: {test_loss:.6f} Loss. Accuracy {accuracy:.2f}%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Modelo entrenado sin augmentation: Test set: 0.747601 Loss. Accuracy 74.12%\n","Modelo entrenado con augmentation: Test set: 0.690253 Loss. Accuracy 78.57%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R8XEXFoo8jfG","executionInfo":{"status":"ok","timestamp":1601504009857,"user_tz":180,"elapsed":271670,"user":{"displayName":"Juan Olloniego","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFZMy1xYdrq8EuW2y-CLv6Eae8Tfe4Qp-uZpYfQQ=s64","userId":"13959738928832749591"}},"outputId":"855791e7-85bc-4a80-c7c6-76e4750ba8b1","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["test_transform = transforms.Compose([\n","  transforms.RandomHorizontalFlip(1),\n","  transforms.ToTensor()                              \n","])\n","\n","_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n","\n","test_loss, accuracy = validation_epoch(modelo_sin_aug, test_loader, criterion)\n","print(f\"Modelo entrenado sin augmentation: Test set: {test_loss:.6f} Loss. Accuracy {accuracy:.2f}%\")\n","\n","test_loss, accuracy = validation_epoch(modelo_con_aug, test_loader, criterion)\n","print(f\"Modelo entrenado con augmentation: Test set: {test_loss:.6f} Loss. Accuracy {accuracy:.2f}%\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Modelo entrenado sin augmentation: Test set: 0.757754 Loss. Accuracy 73.87%\n","Modelo entrenado con augmentation: Test set: 0.750489 Loss. Accuracy 74.64%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X3DMvkFf9EQg","executionInfo":{"status":"ok","timestamp":1601504015753,"user_tz":180,"elapsed":277561,"user":{"displayName":"Juan Olloniego","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFZMy1xYdrq8EuW2y-CLv6Eae8Tfe4Qp-uZpYfQQ=s64","userId":"13959738928832749591"}},"outputId":"5727ef71-ec14-4908-aac2-9fcf18990627","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["test_transform = transforms.Compose([\n","  transforms.RandomVerticalFlip(1),\n","  transforms.ToTensor()                              \n","])\n","\n","_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n","\n","test_loss, accuracy = validation_epoch(modelo_sin_aug, test_loader, criterion)\n","print(f\"Modelo entrenado sin augmentation: Test set: {test_loss:.6f} Loss. Accuracy {accuracy:.2f}%\")\n","\n","test_loss, accuracy = validation_epoch(modelo_con_aug, test_loader, criterion)\n","print(f\"Modelo entrenado con augmentation: Test set: {test_loss:.6f} Loss. Accuracy {accuracy:.2f}%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Modelo entrenado sin augmentation: Test set: 2.127755 Loss. Accuracy 31.93%\n","Modelo entrenado con augmentation: Test set: 1.958503 Loss. Accuracy 33.56%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WsQVBuQKwOvX"},"source":["# DenseNet\n","\n","\n","![Image](https://miro.medium.com/max/5164/1*_Y7-f9GpV7F93siM1js0cg.jpeg)\n","\n","Link al paper original: [DenseNets](https://arxiv.org/pdf/1608.06993.pdf)\n","\n","Algunas consideraciones del paper a tener en cuenta:\n","\n","1. Batch normalization en los inputs de los bloques densos y las capas de transición.\n","2. ReLU en todos lados como funcion de activación.\n","3. El MLP al final de la red cuenta con una capa oculta de 512 neuronas\n","4. Las activaciones luego del tercer bloque denso tienen tamaño 4*4 (ejercicio, calcular a mano!)\n","\n","\n","Implementamos DenseNet para resolver el problema de CIFAR10\n"]},{"cell_type":"code","metadata":{"id":"ZeyVzE9bLUTA"},"source":["class DenseBlock(nn.Module):\n","  def __init__(self, in_channels):\n","    super(DenseBlock, self).__init__()\n","    self.bn = nn.BatchNorm2d(num_features=in_channels)\n","    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, stride=1, padding=1)\n","    self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n","    self.conv3 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n","    self.conv4 = nn.Conv2d(in_channels=96, out_channels=32, kernel_size=3, stride=1, padding=1)\n","    self.conv5 = nn.Conv2d(in_channels=128, out_channels=32, kernel_size=3, stride=1, padding=1)\n","    \n","  def forward(self, x):\n","    bn = self.bn(x)\n","\n","    conv1 = F.relu(self.conv1(x))\n","\n","    conv2 = F.relu(self.conv2(conv1))\n","    c2_dense = torch.cat([conv1, conv2], 1)\n","\n","    conv3 = F.relu(self.conv3(c2_dense))\n","    c3_dense = torch.cat([conv1, conv2, conv3], 1)\n","\n","    conv4 = F.relu(self.conv4(c3_dense))\n","    c4_dense = torch.cat([conv1, conv2, conv3, conv4], 1)\n","\n","    conv5 = F.relu(self.conv5(c4_dense))\n","    c5_dense = torch.cat([conv1, conv2, conv3, conv4, conv5], 1)\n","\n","    return c5_dense"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTjRTakNLVGm"},"source":["class TransitionLayer(nn.Module):\n","  def __init__(self, in_channels, out_channels):\n","    super(TransitionLayer, self).__init__()\n","\n","    self.bn = nn.BatchNorm2d(num_features=in_channels)\n","    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1)\n","    self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n","\n","  def forward(self, x):\n","    bn = self.bn(x)\n","    out = F.relu(self.conv(bn))\n","    out = self.avgpool(out)\n","\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0rglwp_wWEF"},"source":["class DenseNet(nn.Module):\n","\tdef __init__(self, n_classes):\n","\t\tsuper(DenseNet, self).__init__()\n","\n","\t\tself.input_conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, padding=3, bias=False)\n","\n","\t\t# Make Dense Blocks\n","\t\tself.denseblock1 = DenseBlock(in_channels=64)\n","\t\tself.denseblock2 = DenseBlock(in_channels=128)\n","\t\tself.denseblock3 = DenseBlock(in_channels=128)\n","\n","\t\t# Make transition Layers\n","\t\tself.transitionLayer1 = TransitionLayer(in_channels=160, out_channels=128)\n","\t\tself.transitionLayer2 = TransitionLayer(in_channels=160, out_channels=128)\n","\t\tself.transitionLayer3 = TransitionLayer(in_channels=160, out_channels=64)\n","\n","\t\t# Classifier\n","\t\tself.fully_connected_1 = nn.Linear(64*4*4, 512)\n","\t\tself.output = nn.Linear(512, n_classes)\n","\n","\tdef forward(self, x):\n","\t\tout = F.relu(self.input_conv(x))\n","\n","\t\tout = self.denseblock1(out)\n","\t\tout = self.transitionLayer1(out)\n","\n","\t\tout = self.denseblock2(out)\n","\t\tout = self.transitionLayer2(out)\n","\n","\t\tout = self.denseblock3(out)\n","\t\tout = self.transitionLayer3(out)\n","    \n","    out = out.flatten(1)\n","\n","\t\tout = F.relu(self.fully_connected_1(out))\n","\t\tout = self.output(out)\n","\n","\t\treturn out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W7vhkbNiwWIU","executionInfo":{"status":"ok","timestamp":1601510807435,"user_tz":180,"elapsed":371194,"user":{"displayName":"Juan Olloniego","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFZMy1xYdrq8EuW2y-CLv6Eae8Tfe4Qp-uZpYfQQ=s64","userId":"13959738928832749591"}},"outputId":"aa285878-5b88-43e0-b8c3-711e842b7f90","colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["torch.manual_seed(42)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Creamos los datasets\n","test_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor()\n","])\n","\n","densenet = DenseNet(10).to(device)\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.Adam(densenet.parameters(), lr=LR)\n","\n","train_loader, valid_loader, test_loader = get_dataloaders(train_transform, test_transform, BATCH_SIZE)\n","\n","train_model(densenet, train_loader, valid_loader, criterion, optimizer, NUMBER_EPOCHS)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Training epoch 1 | Loss 1.512427 | Accuracy 45.06% | Time 32.96 seconds\n","Validation epoch 1 | Loss 1.223909 | Accuracy 56.30% | Time 3.10 seconds\n","Training epoch 2 | Loss 1.050360 | Accuracy 62.66% | Time 33.86 seconds\n","Validation epoch 2 | Loss 1.053350 | Accuracy 63.09% | Time 3.21 seconds\n","Training epoch 3 | Loss 0.837127 | Accuracy 70.53% | Time 34.00 seconds\n","Validation epoch 3 | Loss 0.922786 | Accuracy 68.48% | Time 3.05 seconds\n","Training epoch 4 | Loss 0.711929 | Accuracy 75.06% | Time 33.89 seconds\n","Validation epoch 4 | Loss 0.847208 | Accuracy 70.80% | Time 3.19 seconds\n","Training epoch 5 | Loss 0.616721 | Accuracy 78.35% | Time 33.99 seconds\n","Validation epoch 5 | Loss 0.810936 | Accuracy 73.61% | Time 3.14 seconds\n","Training epoch 6 | Loss 0.541988 | Accuracy 81.28% | Time 33.87 seconds\n","Validation epoch 6 | Loss 0.683050 | Accuracy 77.28% | Time 3.10 seconds\n","Training epoch 7 | Loss 0.473242 | Accuracy 83.52% | Time 33.81 seconds\n","Validation epoch 7 | Loss 0.722141 | Accuracy 76.91% | Time 3.03 seconds\n","Training epoch 8 | Loss 0.418020 | Accuracy 85.47% | Time 33.85 seconds\n","Validation epoch 8 | Loss 0.680590 | Accuracy 78.50% | Time 3.11 seconds\n","Training epoch 9 | Loss 0.366279 | Accuracy 87.27% | Time 33.74 seconds\n","Validation epoch 9 | Loss 0.669060 | Accuracy 79.18% | Time 3.12 seconds\n","Training epoch 10 | Loss 0.321794 | Accuracy 88.85% | Time 33.72 seconds\n","Validation epoch 10 | Loss 0.709806 | Accuracy 78.22% | Time 2.93 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7G9PbgeDdD_s","executionInfo":{"status":"ok","timestamp":1601510812930,"user_tz":180,"elapsed":5473,"user":{"displayName":"Juan Olloniego","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFZMy1xYdrq8EuW2y-CLv6Eae8Tfe4Qp-uZpYfQQ=s64","userId":"13959738928832749591"}},"outputId":"91dea42e-d41f-4815-9f93-c3b6842a80f4","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["test_transform = transforms.Compose([\n","  transforms.ToTensor()                              \n","])\n","\n","_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n","\n","test_loss, accuracy = validation_epoch(densenet, test_loader, criterion)\n","print(f\"DenseNet Test set: {test_loss:.6f} Loss. Accuracy {accuracy:.2f}%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","DenseNet Test set: 0.688945 Loss. Accuracy 78.57%\n"],"name":"stdout"}]}]}