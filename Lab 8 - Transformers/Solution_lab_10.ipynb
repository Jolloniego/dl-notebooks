{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Solution_lab_10.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hf1xDb60Rn-O"},"source":["# Transformer\n","\n","En este laboratorio vamos a implementar una arquitectura de transformer desde cero. Recuerden usar la GPU de colab para acelerar el entrenamiento."]},{"cell_type":"code","metadata":{"id":"wKeC3ZzoY-cs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605833382807,"user_tz":180,"elapsed":16074,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}},"outputId":"b57ba17b-c983-4d0a-d59a-35001b0fa8a0"},"source":["import copy\n","import math\n","import random\n","import time\n","\n","import pandas as pd\n","import spacy\n","import torch\n","import torch.nn as nn\n","import torchtext\n","from torchtext.data import Field, BucketIterator, TabularDataset\n","from torch import optim\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","\n","DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {DEVICE}\")\n","\n","RANDOM_SEED = 42\n","torch.manual_seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","\n","# Download English and French data from Spacy\n","spacy.cli.download(\"en\")\n","spacy.cli.download(\"fr\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using device: cuda:0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('fr_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/fr\n","You can now load the model via spacy.load('fr')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0ZzQANhYZIkb"},"source":["# Datos\n","\n","Vamos a seguir trabajando con los datos de parejas de oraciones en Frances-w Inglés.\n","\n","    I am cold.    J'ai froid.\n"]},{"cell_type":"code","metadata":{"id":"qxV7Rk_mZNas","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605833398367,"user_tz":180,"elapsed":2193,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}},"outputId":"153c24c7-5c14-49d0-829f-337e441a322b"},"source":["!wget https://download.pytorch.org/tutorial/data.zip\n","!unzip data.zip"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-11-20 00:49:54--  https://download.pytorch.org/tutorial/data.zip\n","Resolving download.pytorch.org (download.pytorch.org)... 13.224.211.24, 13.224.211.74, 13.224.211.45, ...\n","Connecting to download.pytorch.org (download.pytorch.org)|13.224.211.24|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2882130 (2.7M) [application/zip]\n","Saving to: ‘data.zip’\n","\n","data.zip            100%[===================>]   2.75M  6.50MB/s    in 0.4s    \n","\n","2020-11-20 00:49:55 (6.50 MB/s) - ‘data.zip’ saved [2882130/2882130]\n","\n","Archive:  data.zip\n","   creating: data/\n","  inflating: data/eng-fra.txt        \n","   creating: data/names/\n","  inflating: data/names/Arabic.txt   \n","  inflating: data/names/Chinese.txt  \n","  inflating: data/names/Czech.txt    \n","  inflating: data/names/Dutch.txt    \n","  inflating: data/names/English.txt  \n","  inflating: data/names/French.txt   \n","  inflating: data/names/German.txt   \n","  inflating: data/names/Greek.txt    \n","  inflating: data/names/Irish.txt    \n","  inflating: data/names/Italian.txt  \n","  inflating: data/names/Japanese.txt  \n","  inflating: data/names/Korean.txt   \n","  inflating: data/names/Polish.txt   \n","  inflating: data/names/Portuguese.txt  \n","  inflating: data/names/Russian.txt  \n","  inflating: data/names/Scottish.txt  \n","  inflating: data/names/Spanish.txt  \n","  inflating: data/names/Vietnamese.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xIp1UOFPZYuy","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"ok","timestamp":1605833402927,"user_tz":180,"elapsed":2279,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}},"outputId":"b91a323a-95f0-4b1b-e94c-2fff221a9d4b"},"source":["# Take a peek at the dataset\n","dataset = pd.read_csv(\"data/eng-fra.txt\", sep=\"\\t\", header=None)\n","dataset.columns = [\"English\", \"French\"]\n","dataset"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>English</th>\n","      <th>French</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Wow!</td>\n","      <td>Ça alors !</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Fire!</td>\n","      <td>Au feu !</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>135837</th>\n","      <td>A carbon footprint is the amount of carbon dio...</td>\n","      <td>Une empreinte carbone est la somme de pollutio...</td>\n","    </tr>\n","    <tr>\n","      <th>135838</th>\n","      <td>Death is something that we're often discourage...</td>\n","      <td>La mort est une chose qu'on nous décourage sou...</td>\n","    </tr>\n","    <tr>\n","      <th>135839</th>\n","      <td>Since there are usually multiple websites on a...</td>\n","      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n","    </tr>\n","    <tr>\n","      <th>135840</th>\n","      <td>If someone who doesn't know your background sa...</td>\n","      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n","    </tr>\n","    <tr>\n","      <th>135841</th>\n","      <td>It may be impossible to get a completely error...</td>\n","      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>135842 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  English                                             French\n","0                                                     Go.                                               Va !\n","1                                                    Run!                                            Cours !\n","2                                                    Run!                                           Courez !\n","3                                                    Wow!                                         Ça alors !\n","4                                                   Fire!                                           Au feu !\n","...                                                   ...                                                ...\n","135837  A carbon footprint is the amount of carbon dio...  Une empreinte carbone est la somme de pollutio...\n","135838  Death is something that we're often discourage...  La mort est une chose qu'on nous décourage sou...\n","135839  Since there are usually multiple websites on a...  Puisqu'il y a de multiples sites web sur chaqu...\n","135840  If someone who doesn't know your background sa...  Si quelqu'un qui ne connaît pas vos antécédent...\n","135841  It may be impossible to get a completely error...  Il est peut-être impossible d'obtenir un Corpu...\n","\n","[135842 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"ScPj8X66po4c","executionInfo":{"status":"ok","timestamp":1605833402928,"user_tz":180,"elapsed":1695,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["# dataset = dataset.sample(int(len(dataset)*0.4))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQdP-OPws-82","executionInfo":{"status":"ok","timestamp":1605833403959,"user_tz":180,"elapsed":2189,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["# Remove very long sentences\n","\n","MAX_SEQ_LEN = 50\n","\n","dataset['en_len'] = dataset['English'].str.count(' ')\n","dataset['fr_len'] = dataset['French'].str.count(' ')\n","dataset = dataset[\n","    (dataset['fr_len'] < MAX_SEQ_LEN) & \n","    (dataset['en_len'] < MAX_SEQ_LEN)\n","][['English', 'French']]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cb0hfkkpulUK","executionInfo":{"status":"ok","timestamp":1605833403960,"user_tz":180,"elapsed":1491,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["# Split dataset into train, val and test\n","train, val_test = train_test_split(dataset, test_size=0.2, random_state=RANDOM_SEED)\n","val, test = train_test_split(val_test, test_size=0.5)\n","\n","# Save splits to CSV files\n","train.to_csv(\"train.csv\", index=False)\n","val.to_csv(\"val.csv\", index=False)\n","test.to_csv(\"test.csv\", index=False)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"aX1sIWsFq7rB","executionInfo":{"status":"ok","timestamp":1605833416165,"user_tz":180,"elapsed":11503,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["# Load English and French models\n","en = spacy.load('en')\n","fr = spacy.load('fr')\n","\n","def tokenize_en(sentence):\n","    return [tok.text for tok in en.tokenizer(sentence)]\n","  \n","def tokenize_fr(sentence):\n","    return [tok.text for tok in fr.tokenizer(sentence)]\n","\n","EN_TEXT = Field(tokenize=tokenize_en, fix_length=MAX_SEQ_LEN)\n","FR_TEXT = Field(tokenize=tokenize_fr, init_token = \"<sos>\", eos_token = \"<eos>\", fix_length=MAX_SEQ_LEN)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HOh05JVfydM9","executionInfo":{"status":"ok","timestamp":1605833425158,"user_tz":180,"elapsed":14686,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["# Associate the text in the 'English' column with the EN_TEXT field,\n","# and 'French' with FR_TEXT\n","data_fields = [('English', EN_TEXT), ('French', FR_TEXT)]\n","\n","train, val = TabularDataset.splits(\n","    path='./',\n","    train='train.csv',\n","    validation='val.csv',\n","    format='csv',\n","    fields=data_fields\n",")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mAjoiHS4BH7","executionInfo":{"status":"ok","timestamp":1605833426057,"user_tz":180,"elapsed":14591,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["# Build vocabularies\n","FR_TEXT.build_vocab(train, val)\n","EN_TEXT.build_vocab(train, val)\n","\n","# Construct a train iterator\n","train_iter = BucketIterator(\n","    train,\n","    batch_size=32,\n","    sort_key=lambda x: len(x.French),\n","    shuffle=True\n",")"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TO8tpkFPbdpN"},"source":["# Armando el transformer paso a paso"]},{"cell_type":"markdown","metadata":{"id":"Lur0pJDoW8Hh"},"source":["![Transformer architecture](https://miro.medium.com/max/1140/1*2vyKzFlzIHfSmOU_lnQE4A.png)\n","\n","El diagrama ilustra el modelo que vamos a implementar. Los inputs al encoder son las oraciones en Frances, y los \"Outputs\" que entran al decoder son las sentencias en Inglés.\n","\n","Necesitamos entender 5 procesos para implementar el modelo:\n","- Embedding de los inputs\n","- Encoding Posicional\n","- Creación de máscaras\n","- La capa de Multi-Head Attention\n","- La capa Feed-Forward"]},{"cell_type":"markdown","metadata":{"id":"j6ULN-z2W8DJ"},"source":["## Encoding Posicional\n","----\n","El embedding de cada palabra aprende su significado, ahora necesitamos una manera de que la red aprenda sobre la posicion de cada palabra en la sentencia.\n","\n","[Vaswani *et al.*](https://arxiv.org/abs/1706.03762) respondió esta pregunta usando las siguientes funciones para crear valores constantes relacionados a cada posición:\n","\n","$$ PE_{(pos, 2i)} = sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right) $$\n","$$ PE_{(pos, 2i+1)} = cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right) $$\n","\n","Esta constante es una matriz en 2D con una de las dimensiones de igual tamaño que los embeddings y la otra igual a la cantidad de palabras en la sentencia.\n","\n","![Positional encoding matrix](https://miro.medium.com/max/1359/1*B-VR6R5vJl3Y7jbMNf5Fpw.png)\n","\n","![Positional encoding example](http://jalammar.github.io/images/t/transformer_positional_encoding_example.png)"]},{"cell_type":"code","metadata":{"id":"G7aRi6k5f-dk","executionInfo":{"status":"ok","timestamp":1605833426059,"user_tz":180,"elapsed":12913,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["class PositionalEncoder(nn.Module):\n","    def __init__(self, d_model, max_seq_len=MAX_SEQ_LEN, dropout=0.1):\n","        super(PositionalEncoder, self).__init__()\n","        self.d_model = d_model\n","        self.dropout = nn.Dropout(dropout)\n","        \n","        # Create constant 'pe' matrix with values dependant on pos and i\n","        pe = torch.zeros(max_seq_len, d_model)\n","        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n","        div_term = 1.0 / torch.pow(10000, torch.arange(0, d_model, 2).float() / d_model)\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","\n","\n","        # We register them as a buffer so the optimzer doesn't see this as parameters of the model to optimize!\n","        self.register_buffer('pe', pe)\n"," \n","    \n","    def forward(self, x):\n","        # Make embeddings relatively larger\n","        x = x * math.sqrt(self.d_model)\n","        # Add constant to embedding\n","        x = x + self.pe[:, :x.size(1), :]\n","        return self.dropout(x)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pv2ZLhMqW79c"},"source":["## Máscaras para los inputs\n","----\n","Las máscaras de ceros cumplen dos propósitos:\n","\n","- En **ambos** encoder y decoder: Para obtener 0s en la atención sobre el padding.\n","- En el **decoder**: Prevenir que el decoder \"espíe\" a los siguientes inputs de la secuencia traducida, el futuro que no debería conocer para predecir la siguiente palabra. Evita que el decoder \"vea\" lo que tiene que predecir antes de predecirlo."]},{"cell_type":"code","metadata":{"id":"nqDBxGZg5xOq","executionInfo":{"status":"ok","timestamp":1605833426060,"user_tz":180,"elapsed":12101,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["def build_attn_pad_mask(seq, pad_index):\n","    # Creates mask with 0s wherever there is padding in the input\n","    return (seq != pad_index).unsqueeze(1).type(torch.uint8)\n","\n","\n","def build_nopeak_mask(size):\n","    # Creates mask with 1s up until the the index of the word being predicted\n","    nopeak_mask = torch.triu(torch.ones(size, size)).transpose(0, 1)\n","    return nopeak_mask.unsqueeze(0).type(torch.uint8)\n","\n","def create_masks(src, src_pad, trg=None, trg_pad=None):\n","    src_mask = build_attn_pad_mask(src, src_pad)\n","\n","    if trg is not None:\n","        trg_mask = build_attn_pad_mask(trg, trg_pad)\n","        size = trg.size(1) # get seq_len for matrix\n","        np_mask = build_nopeak_mask(size)\n","        trg_mask = trg_mask & np_mask\n","    else: \n","        trg_mask = None\n","\n","    return src_mask, trg_mask"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dulPyzCqW74v"},"source":["## Multi-Head Attention\n","----\n","\n","![Multihead attention schema](https://miro.medium.com/max/1254/1*1tsRtfaY9z6HxmERYhw8XQ.png)\n","\n","$V$, $K$ y $Q$ reprensentan ‘key’, ‘value’ and ‘query’. En el caso del Encoder, $V$, $K$ and $Q$ serán simplemente copias idénticas del vector de embedding (junto con el encoding posicional). Tendrán las siguientes dimensiones $\\text{batch_size} \\times \\text{seq_len} \\times d_\\text{model}$.\n","\n","En multi-head attention repartimos el vector de embedding en $N$ cabezas, por lo que tendrán las dimensiones: $\\text{batch_size} \\times N \\times \\text{seq_len} \\times (d_{\\text{model}} / N)$.\n","\n","La dimensión final: ($d_{\\text{model}} / N$) es a lo que llamaremos $d_k$."]},{"cell_type":"code","metadata":{"id":"s-_fobf8E7pD","executionInfo":{"status":"ok","timestamp":1605833426061,"user_tz":180,"elapsed":11236,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, heads, d_model, attn_pdrop = 0.1, resid_pdrop = 0.1):\n","        super(MultiHeadAttention, self).__init__()\n","        \n","        self.d_model = d_model\n","        self.d_k = d_model // heads\n","        self.h = heads\n","        \n","        self.q_linear = nn.Linear(d_model, d_model)\n","        self.v_linear = nn.Linear(d_model, d_model)\n","        self.k_linear = nn.Linear(d_model, d_model)\n","\n","        # Regularization\n","        self.attn_dropout = nn.Dropout(attn_pdrop)\n","        self.resid_dropout = nn.Dropout(resid_pdrop)\n","\n","        # Output projection\n","        self.out = nn.Linear(d_model, d_model)\n","    \n","    def forward(self, q, k, v, mask=None):\n","        # Get batch size\n","        bs = q.size(0)\n","        \n","        # Perform linear operation and split into h heads\n","        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n","        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n","        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n","        \n","        # Transpose to get dimensions bs * h * sl * d_model\n","        k = k.transpose(1,2)\n","        q = q.transpose(1,2)\n","        v = v.transpose(1,2)\n","        \n","        # Calculate attention using function we will define next\n","        \n","        scores = attention(q, k, v, self.d_k, mask, self.attn_dropout)\n","\n","        # Re-assemble all head outputs side by side\n","        # Need to use contigous here to get correspondence between the tensor\n","        # indices and the memory layout\n","        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n","        \n","        # Output projection\n","        output = self.resid_dropout(self.out(concat))\n","\n","        return output"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W28fJmT9HXGk"},"source":["### Mecanismo de Atención\n","----\n","\n","![Attention diagram](https://miro.medium.com/max/336/1*15E9qKg9bKnWdSRWCyY2iA.png)\n","![Attention equation](https://miro.medium.com/max/1068/1*evdACdTOBT5j1g1nXialBg.png)\n","\n","Inicialmente, multiplicamos $Q$ por la transpuesta de $K$. Esto es luego dividipo por $\\sqrt{d_k}$ (normalización).\n","\n","Algo que aún no vimos es qué hacer con atención y las máscaras. Antes de hacer el Softmax, aplicamos nuestra máscara de ceros para reducir los valores donde el input es padding (o futuro).\n","\n","Finalmente, el último paso es hacer el producto (dot product) entre el resultado hasta ahora y $V$."]},{"cell_type":"code","metadata":{"id":"gQTmzZ35Je5W","executionInfo":{"status":"ok","timestamp":1605833426062,"user_tz":180,"elapsed":10429,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["def attention(q, k, v, d_k, mask=None, dropout=None):\n","    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n","    \n","    if mask is not None:\n","        mask = mask.unsqueeze(1)\n","        scores = scores.masked_fill(mask == 0, -1e9)\n","        scores = F.softmax(scores, dim=-1)\n","    \n","    if dropout is not None:\n","        scores = dropout(scores)\n","        \n","    output = torch.matmul(scores, v)\n","    return output"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"97KT06QVcELb"},"source":["## Capa Feed-Forward\n","----\n","Esta capa solo consiste en dos opeaciones lineales (nn.Linear) con ReLU y dropout entre ellas."]},{"cell_type":"code","metadata":{"id":"hXXhptZ3JvhC","executionInfo":{"status":"ok","timestamp":1605833426062,"user_tz":180,"elapsed":9473,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n","        super(FeedForward, self).__init__()\n","\n","        # We set d_ff as a default to 2048\n","        self.linear_1 = nn.Linear(d_model, d_ff)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear_2 = nn.Linear(d_ff, d_model)\n","\n","    def forward(self, x):\n","        x = self.dropout(F.relu(self.linear_1(x)))\n","        x = self.linear_2(x)\n","        return x"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4q4nextzKJFO"},"source":["# Combinando todo\n","\n","Vamos a crear una capa EncoderLayer y DecoderLayer que agrupan los componentes necesarios para crear un solo encoder (o decoder).\n","\n","Luego, creamos el Encoder de nuestra arquitectura, conteniendo N de estos bloques anteriores. Repetimos para el decoder.\n","\n","![Transformer architecture](https://miro.medium.com/max/1140/1*2vyKzFlzIHfSmOU_lnQE4A.png)\n"]},{"cell_type":"code","metadata":{"id":"MD-7Yks3K31b","executionInfo":{"status":"ok","timestamp":1605833431658,"user_tz":180,"elapsed":1038,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["# Build an encoder layer with one multi-head attention layer and one\n","# feed-forward layer\n","class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout = 0.1):\n","        super(EncoderLayer, self).__init__()\n","        self.attn = MultiHeadAttention(heads, d_model, dropout, dropout)\n","        self.ff = FeedForward(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x, mask):\n","        x = x + self.dropout(self.attn(x, x, x, mask))\n","        x = x + self.dropout(self.ff(x))\n","        return x\n","    \n","# Build a decoder layer with two multi-head attention layers and\n","# one feed-forward layer\n","class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout=0.1):\n","        super(DecoderLayer, self).__init__()\n","        self.dropout = nn.Dropout(dropout)\n","        \n","        self.attn_1 = MultiHeadAttention(heads, d_model)\n","        self.attn_2 = MultiHeadAttention(heads, d_model)\n","        self.ff = FeedForward(d_model)\n","\n","    def forward(self, x, e_outputs, src_mask, trg_mask):\n","        x = x + self.dropout(self.attn_1(x, x, x, trg_mask))\n","        x = x + self.dropout(self.attn_2(x, e_outputs, e_outputs, src_mask))\n","        x = x + self.dropout(self.ff(x))\n","        return x\n","\n","# Convenient cloning function that can generate multiple layers:\n","def get_clones(module, N):\n","    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QMVOFpaKK2z","executionInfo":{"status":"ok","timestamp":1605833431659,"user_tz":180,"elapsed":785,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["class Encoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super(Encoder, self).__init__()\n","        self.N = N\n","        self.embed = nn.Embedding(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model)\n","        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n","\n","    def forward(self, src, mask):\n","        x = self.embed(src)\n","        x = self.pe(x)\n","        for i in range(N):\n","            x = self.layers[i](x, mask)\n","        return x\n","    \n","class Decoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super(Decoder, self).__init__()\n","        self.N = N\n","        self.embed = nn.Embedding(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model)\n","        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n","\n","    def forward(self, trg, e_outputs, src_mask, trg_mask):\n","        x = self.embed(trg)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n","        return x"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VUxlnAGv-AMu"},"source":["Finalmente usando los dos bloques anteriores y una capa linear creamos el transformer con $N$ encoders/decoders!"]},{"cell_type":"code","metadata":{"id":"58aNa611MsK_","executionInfo":{"status":"ok","timestamp":1605833432066,"user_tz":180,"elapsed":468,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["class Transformer(nn.Module):\n","    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n","        super(Transformer, self).__init__()\n","        self.encoder = Encoder(src_vocab, d_model, N, heads)\n","        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n","        self.out = nn.Linear(d_model, trg_vocab)\n","\n","    def forward(self, src, trg, src_mask, trg_mask):\n","        e_outputs = self.encoder(src, src_mask)\n","        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n","        output = self.out(d_output)\n","        return output"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YSYVGuqCM-Hn"},"source":["# Entrenando"]},{"cell_type":"code","metadata":{"id":"0Wun9klgM9AN","executionInfo":{"status":"ok","timestamp":1605833450754,"user_tz":180,"elapsed":11138,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["d_model = 128\n","heads = 4\n","N = 3\n","src_vocab = len(EN_TEXT.vocab)\n","trg_vocab = len(FR_TEXT.vocab)\n","\n","model = Transformer(src_vocab, trg_vocab, d_model, N, heads).to(DEVICE)\n","\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","# This code is very important! It initialises the parameters with a\n","# range of values that stops the signal fading or getting too big.\n","# See this blog for a mathematical explanation:\n","# https://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNKzh6dLNYVR","executionInfo":{"status":"ok","timestamp":1605833450756,"user_tz":180,"elapsed":8733,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["def train_model(epochs, print_every=100):\n","    model.train()\n","    \n","    start = time.time()\n","    temp = start\n","    total_loss = 0\n","\n","    src_pad = EN_TEXT.vocab.stoi['<pad>']\n","    trg_pad = FR_TEXT.vocab.stoi['<pad>']\n","\n","    for epoch in range(epochs):\n","        total_loss = 0       \n","        for i, batch in enumerate(train_iter):\n","            src = batch.English.transpose(0, 1)\n","            trg = batch.French.transpose(0, 1)\n","            # the French sentence we input has all words except\n","            # the last, as it is using each word to predict the next\n","            trg_input = trg[:, :-1]\n","            \n","            # the words we are trying to predict\n","            targets = trg[:, 1:].contiguous().view(-1)\n","            \n","            # create function to make masks using mask code above\n","            src_mask, trg_mask = create_masks(src, src_pad, trg_input, trg_pad)\n","\n","            preds = model(src.to(DEVICE), trg_input.to(DEVICE), src_mask.to(DEVICE), trg_mask.to(DEVICE))\n","\n","            optim.zero_grad()\n","\n","            loss = F.cross_entropy(\n","                preds.view(-1, preds.size(-1)),\n","                targets.to(DEVICE),\n","                ignore_index=trg_pad\n","            )\n","            loss.backward()\n","            optim.step()\n","            total_loss += loss.item()\n","            if (i + 1) % print_every == 0:\n","                loss_avg = total_loss / print_every\n","                print(\"time = %dm, epoch %d, iter = %d, loss = %.3f, %ds per %d iters\" % (\n","                    (time.time() - start) // 60, epoch + 1, i + 1, loss_avg, time.time() - temp, print_every)\n","                )\n","                total_loss = 0\n","                temp = time.time()"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"jGfw-ZZffh5P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605835105369,"user_tz":180,"elapsed":1661350,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}},"outputId":"1b550c36-2450-4e2a-bdd5-2455f3ec1725"},"source":["optim = torch.optim.Adam(model.parameters(), lr=0.0002)\n","\n","train_model(10)  "],"execution_count":20,"outputs":[{"output_type":"stream","text":["time = 0m, epoch 1, iter = 100, loss = 6.535, 5s per 100 iters\n","time = 0m, epoch 1, iter = 200, loss = 5.489, 4s per 100 iters\n","time = 0m, epoch 1, iter = 300, loss = 5.119, 4s per 100 iters\n","time = 0m, epoch 1, iter = 400, loss = 4.813, 4s per 100 iters\n","time = 0m, epoch 1, iter = 500, loss = 4.682, 4s per 100 iters\n","time = 0m, epoch 1, iter = 600, loss = 4.536, 4s per 100 iters\n","time = 0m, epoch 1, iter = 700, loss = 4.384, 4s per 100 iters\n","time = 0m, epoch 1, iter = 800, loss = 4.251, 4s per 100 iters\n","time = 0m, epoch 1, iter = 900, loss = 4.131, 4s per 100 iters\n","time = 0m, epoch 1, iter = 1000, loss = 4.004, 4s per 100 iters\n","time = 0m, epoch 1, iter = 1100, loss = 3.930, 4s per 100 iters\n","time = 0m, epoch 1, iter = 1200, loss = 3.810, 4s per 100 iters\n","time = 1m, epoch 1, iter = 1300, loss = 3.712, 4s per 100 iters\n","time = 1m, epoch 1, iter = 1400, loss = 3.645, 4s per 100 iters\n","time = 1m, epoch 1, iter = 1500, loss = 3.547, 4s per 100 iters\n","time = 1m, epoch 1, iter = 1600, loss = 3.507, 4s per 100 iters\n","time = 1m, epoch 1, iter = 1700, loss = 3.411, 4s per 100 iters\n","time = 1m, epoch 1, iter = 1800, loss = 3.335, 4s per 100 iters\n","time = 1m, epoch 1, iter = 1900, loss = 3.271, 4s per 100 iters\n","time = 1m, epoch 1, iter = 2000, loss = 3.211, 4s per 100 iters\n","time = 1m, epoch 1, iter = 2100, loss = 3.147, 4s per 100 iters\n","time = 1m, epoch 1, iter = 2200, loss = 3.100, 4s per 100 iters\n","time = 1m, epoch 1, iter = 2300, loss = 3.055, 4s per 100 iters\n","time = 1m, epoch 1, iter = 2400, loss = 3.023, 4s per 100 iters\n","time = 2m, epoch 1, iter = 2500, loss = 2.956, 4s per 100 iters\n","time = 2m, epoch 1, iter = 2600, loss = 2.916, 4s per 100 iters\n","time = 2m, epoch 1, iter = 2700, loss = 2.886, 4s per 100 iters\n","time = 2m, epoch 1, iter = 2800, loss = 2.864, 4s per 100 iters\n","time = 2m, epoch 1, iter = 2900, loss = 2.806, 4s per 100 iters\n","time = 2m, epoch 1, iter = 3000, loss = 2.790, 4s per 100 iters\n","time = 2m, epoch 1, iter = 3100, loss = 2.713, 4s per 100 iters\n","time = 2m, epoch 1, iter = 3200, loss = 2.682, 4s per 100 iters\n","time = 2m, epoch 1, iter = 3300, loss = 2.672, 4s per 100 iters\n","time = 2m, epoch 2, iter = 100, loss = 2.467, 9s per 100 iters\n","time = 2m, epoch 2, iter = 200, loss = 2.478, 4s per 100 iters\n","time = 2m, epoch 2, iter = 300, loss = 2.454, 4s per 100 iters\n","time = 3m, epoch 2, iter = 400, loss = 2.421, 4s per 100 iters\n","time = 3m, epoch 2, iter = 500, loss = 2.397, 4s per 100 iters\n","time = 3m, epoch 2, iter = 600, loss = 2.377, 4s per 100 iters\n","time = 3m, epoch 2, iter = 700, loss = 2.346, 4s per 100 iters\n","time = 3m, epoch 2, iter = 800, loss = 2.301, 4s per 100 iters\n","time = 3m, epoch 2, iter = 900, loss = 2.334, 4s per 100 iters\n","time = 3m, epoch 2, iter = 1000, loss = 2.295, 4s per 100 iters\n","time = 3m, epoch 2, iter = 1100, loss = 2.281, 4s per 100 iters\n","time = 3m, epoch 2, iter = 1200, loss = 2.279, 4s per 100 iters\n","time = 3m, epoch 2, iter = 1300, loss = 2.292, 5s per 100 iters\n","time = 3m, epoch 2, iter = 1400, loss = 2.242, 4s per 100 iters\n","time = 3m, epoch 2, iter = 1500, loss = 2.235, 5s per 100 iters\n","time = 4m, epoch 2, iter = 1600, loss = 2.191, 4s per 100 iters\n","time = 4m, epoch 2, iter = 1700, loss = 2.183, 4s per 100 iters\n","time = 4m, epoch 2, iter = 1800, loss = 2.167, 4s per 100 iters\n","time = 4m, epoch 2, iter = 1900, loss = 2.163, 4s per 100 iters\n","time = 4m, epoch 2, iter = 2000, loss = 2.097, 4s per 100 iters\n","time = 4m, epoch 2, iter = 2100, loss = 2.139, 4s per 100 iters\n","time = 4m, epoch 2, iter = 2200, loss = 2.164, 4s per 100 iters\n","time = 4m, epoch 2, iter = 2300, loss = 2.098, 4s per 100 iters\n","time = 4m, epoch 2, iter = 2400, loss = 2.104, 4s per 100 iters\n","time = 4m, epoch 2, iter = 2500, loss = 2.089, 4s per 100 iters\n","time = 4m, epoch 2, iter = 2600, loss = 2.096, 4s per 100 iters\n","time = 4m, epoch 2, iter = 2700, loss = 2.100, 4s per 100 iters\n","time = 5m, epoch 2, iter = 2800, loss = 2.083, 4s per 100 iters\n","time = 5m, epoch 2, iter = 2900, loss = 2.029, 4s per 100 iters\n","time = 5m, epoch 2, iter = 3000, loss = 2.045, 4s per 100 iters\n","time = 5m, epoch 2, iter = 3100, loss = 1.984, 4s per 100 iters\n","time = 5m, epoch 2, iter = 3200, loss = 2.012, 4s per 100 iters\n","time = 5m, epoch 2, iter = 3300, loss = 2.013, 4s per 100 iters\n","time = 5m, epoch 3, iter = 100, loss = 1.812, 9s per 100 iters\n","time = 5m, epoch 3, iter = 200, loss = 1.798, 4s per 100 iters\n","time = 5m, epoch 3, iter = 300, loss = 1.785, 4s per 100 iters\n","time = 5m, epoch 3, iter = 400, loss = 1.803, 4s per 100 iters\n","time = 5m, epoch 3, iter = 500, loss = 1.779, 4s per 100 iters\n","time = 5m, epoch 3, iter = 600, loss = 1.782, 4s per 100 iters\n","time = 6m, epoch 3, iter = 700, loss = 1.832, 4s per 100 iters\n","time = 6m, epoch 3, iter = 800, loss = 1.815, 4s per 100 iters\n","time = 6m, epoch 3, iter = 900, loss = 1.781, 4s per 100 iters\n","time = 6m, epoch 3, iter = 1000, loss = 1.773, 4s per 100 iters\n","time = 6m, epoch 3, iter = 1100, loss = 1.787, 4s per 100 iters\n","time = 6m, epoch 3, iter = 1200, loss = 1.762, 4s per 100 iters\n","time = 6m, epoch 3, iter = 1300, loss = 1.784, 4s per 100 iters\n","time = 6m, epoch 3, iter = 1400, loss = 1.771, 4s per 100 iters\n","time = 6m, epoch 3, iter = 1500, loss = 1.744, 4s per 100 iters\n","time = 6m, epoch 3, iter = 1600, loss = 1.717, 4s per 100 iters\n","time = 6m, epoch 3, iter = 1700, loss = 1.740, 4s per 100 iters\n","time = 6m, epoch 3, iter = 1800, loss = 1.738, 4s per 100 iters\n","time = 7m, epoch 3, iter = 1900, loss = 1.734, 4s per 100 iters\n","time = 7m, epoch 3, iter = 2000, loss = 1.762, 4s per 100 iters\n","time = 7m, epoch 3, iter = 2100, loss = 1.732, 4s per 100 iters\n","time = 7m, epoch 3, iter = 2200, loss = 1.754, 4s per 100 iters\n","time = 7m, epoch 3, iter = 2300, loss = 1.753, 4s per 100 iters\n","time = 7m, epoch 3, iter = 2400, loss = 1.702, 4s per 100 iters\n","time = 7m, epoch 3, iter = 2500, loss = 1.720, 4s per 100 iters\n","time = 7m, epoch 3, iter = 2600, loss = 1.676, 4s per 100 iters\n","time = 7m, epoch 3, iter = 2700, loss = 1.669, 4s per 100 iters\n","time = 7m, epoch 3, iter = 2800, loss = 1.673, 4s per 100 iters\n","time = 7m, epoch 3, iter = 2900, loss = 1.670, 4s per 100 iters\n","time = 7m, epoch 3, iter = 3000, loss = 1.690, 4s per 100 iters\n","time = 8m, epoch 3, iter = 3100, loss = 1.720, 4s per 100 iters\n","time = 8m, epoch 3, iter = 3200, loss = 1.676, 4s per 100 iters\n","time = 8m, epoch 3, iter = 3300, loss = 1.638, 4s per 100 iters\n","time = 8m, epoch 4, iter = 100, loss = 1.490, 9s per 100 iters\n","time = 8m, epoch 4, iter = 200, loss = 1.480, 4s per 100 iters\n","time = 8m, epoch 4, iter = 300, loss = 1.511, 4s per 100 iters\n","time = 8m, epoch 4, iter = 400, loss = 1.488, 4s per 100 iters\n","time = 8m, epoch 4, iter = 500, loss = 1.508, 4s per 100 iters\n","time = 8m, epoch 4, iter = 600, loss = 1.497, 4s per 100 iters\n","time = 8m, epoch 4, iter = 700, loss = 1.511, 4s per 100 iters\n","time = 8m, epoch 4, iter = 800, loss = 1.502, 4s per 100 iters\n","time = 8m, epoch 4, iter = 900, loss = 1.507, 4s per 100 iters\n","time = 9m, epoch 4, iter = 1000, loss = 1.498, 4s per 100 iters\n","time = 9m, epoch 4, iter = 1100, loss = 1.474, 5s per 100 iters\n","time = 9m, epoch 4, iter = 1200, loss = 1.506, 4s per 100 iters\n","time = 9m, epoch 4, iter = 1300, loss = 1.531, 4s per 100 iters\n","time = 9m, epoch 4, iter = 1400, loss = 1.494, 4s per 100 iters\n","time = 9m, epoch 4, iter = 1500, loss = 1.465, 4s per 100 iters\n","time = 9m, epoch 4, iter = 1600, loss = 1.489, 4s per 100 iters\n","time = 9m, epoch 4, iter = 1700, loss = 1.475, 4s per 100 iters\n","time = 9m, epoch 4, iter = 1800, loss = 1.485, 4s per 100 iters\n","time = 9m, epoch 4, iter = 1900, loss = 1.484, 4s per 100 iters\n","time = 9m, epoch 4, iter = 2000, loss = 1.484, 4s per 100 iters\n","time = 9m, epoch 4, iter = 2100, loss = 1.497, 4s per 100 iters\n","time = 10m, epoch 4, iter = 2200, loss = 1.478, 4s per 100 iters\n","time = 10m, epoch 4, iter = 2300, loss = 1.483, 5s per 100 iters\n","time = 10m, epoch 4, iter = 2400, loss = 1.472, 4s per 100 iters\n","time = 10m, epoch 4, iter = 2500, loss = 1.507, 4s per 100 iters\n","time = 10m, epoch 4, iter = 2600, loss = 1.482, 4s per 100 iters\n","time = 10m, epoch 4, iter = 2700, loss = 1.468, 4s per 100 iters\n","time = 10m, epoch 4, iter = 2800, loss = 1.472, 4s per 100 iters\n","time = 10m, epoch 4, iter = 2900, loss = 1.472, 5s per 100 iters\n","time = 10m, epoch 4, iter = 3000, loss = 1.461, 4s per 100 iters\n","time = 10m, epoch 4, iter = 3100, loss = 1.481, 4s per 100 iters\n","time = 10m, epoch 4, iter = 3200, loss = 1.467, 4s per 100 iters\n","time = 10m, epoch 4, iter = 3300, loss = 1.469, 4s per 100 iters\n","time = 11m, epoch 5, iter = 100, loss = 1.300, 9s per 100 iters\n","time = 11m, epoch 5, iter = 200, loss = 1.286, 5s per 100 iters\n","time = 11m, epoch 5, iter = 300, loss = 1.271, 4s per 100 iters\n","time = 11m, epoch 5, iter = 400, loss = 1.305, 4s per 100 iters\n","time = 11m, epoch 5, iter = 500, loss = 1.280, 4s per 100 iters\n","time = 11m, epoch 5, iter = 600, loss = 1.315, 4s per 100 iters\n","time = 11m, epoch 5, iter = 700, loss = 1.302, 4s per 100 iters\n","time = 11m, epoch 5, iter = 800, loss = 1.345, 4s per 100 iters\n","time = 11m, epoch 5, iter = 900, loss = 1.295, 4s per 100 iters\n","time = 11m, epoch 5, iter = 1000, loss = 1.325, 4s per 100 iters\n","time = 11m, epoch 5, iter = 1100, loss = 1.312, 4s per 100 iters\n","time = 12m, epoch 5, iter = 1200, loss = 1.295, 4s per 100 iters\n","time = 12m, epoch 5, iter = 1300, loss = 1.339, 4s per 100 iters\n","time = 12m, epoch 5, iter = 1400, loss = 1.285, 4s per 100 iters\n","time = 12m, epoch 5, iter = 1500, loss = 1.327, 4s per 100 iters\n","time = 12m, epoch 5, iter = 1600, loss = 1.339, 4s per 100 iters\n","time = 12m, epoch 5, iter = 1700, loss = 1.276, 4s per 100 iters\n","time = 12m, epoch 5, iter = 1800, loss = 1.345, 4s per 100 iters\n","time = 12m, epoch 5, iter = 1900, loss = 1.311, 4s per 100 iters\n","time = 12m, epoch 5, iter = 2000, loss = 1.323, 4s per 100 iters\n","time = 12m, epoch 5, iter = 2100, loss = 1.327, 4s per 100 iters\n","time = 12m, epoch 5, iter = 2200, loss = 1.317, 4s per 100 iters\n","time = 12m, epoch 5, iter = 2300, loss = 1.308, 5s per 100 iters\n","time = 12m, epoch 5, iter = 2400, loss = 1.352, 5s per 100 iters\n","time = 13m, epoch 5, iter = 2500, loss = 1.306, 4s per 100 iters\n","time = 13m, epoch 5, iter = 2600, loss = 1.337, 4s per 100 iters\n","time = 13m, epoch 5, iter = 2700, loss = 1.337, 4s per 100 iters\n","time = 13m, epoch 5, iter = 2800, loss = 1.302, 4s per 100 iters\n","time = 13m, epoch 5, iter = 2900, loss = 1.323, 4s per 100 iters\n","time = 13m, epoch 5, iter = 3000, loss = 1.297, 4s per 100 iters\n","time = 13m, epoch 5, iter = 3100, loss = 1.323, 4s per 100 iters\n","time = 13m, epoch 5, iter = 3200, loss = 1.325, 4s per 100 iters\n","time = 13m, epoch 5, iter = 3300, loss = 1.288, 4s per 100 iters\n","time = 13m, epoch 6, iter = 100, loss = 1.139, 9s per 100 iters\n","time = 13m, epoch 6, iter = 200, loss = 1.159, 4s per 100 iters\n","time = 14m, epoch 6, iter = 300, loss = 1.152, 5s per 100 iters\n","time = 14m, epoch 6, iter = 400, loss = 1.144, 4s per 100 iters\n","time = 14m, epoch 6, iter = 500, loss = 1.155, 4s per 100 iters\n","time = 14m, epoch 6, iter = 600, loss = 1.148, 5s per 100 iters\n","time = 14m, epoch 6, iter = 700, loss = 1.156, 4s per 100 iters\n","time = 14m, epoch 6, iter = 800, loss = 1.181, 4s per 100 iters\n","time = 14m, epoch 6, iter = 900, loss = 1.199, 4s per 100 iters\n","time = 14m, epoch 6, iter = 1000, loss = 1.169, 4s per 100 iters\n","time = 14m, epoch 6, iter = 1100, loss = 1.185, 4s per 100 iters\n","time = 14m, epoch 6, iter = 1200, loss = 1.167, 4s per 100 iters\n","time = 14m, epoch 6, iter = 1300, loss = 1.182, 4s per 100 iters\n","time = 14m, epoch 6, iter = 1400, loss = 1.185, 4s per 100 iters\n","time = 15m, epoch 6, iter = 1500, loss = 1.181, 4s per 100 iters\n","time = 15m, epoch 6, iter = 1600, loss = 1.200, 5s per 100 iters\n","time = 15m, epoch 6, iter = 1700, loss = 1.219, 4s per 100 iters\n","time = 15m, epoch 6, iter = 1800, loss = 1.191, 4s per 100 iters\n","time = 15m, epoch 6, iter = 1900, loss = 1.205, 4s per 100 iters\n","time = 15m, epoch 6, iter = 2000, loss = 1.186, 4s per 100 iters\n","time = 15m, epoch 6, iter = 2100, loss = 1.194, 4s per 100 iters\n","time = 15m, epoch 6, iter = 2200, loss = 1.202, 4s per 100 iters\n","time = 15m, epoch 6, iter = 2300, loss = 1.215, 4s per 100 iters\n","time = 15m, epoch 6, iter = 2400, loss = 1.202, 4s per 100 iters\n","time = 15m, epoch 6, iter = 2500, loss = 1.202, 4s per 100 iters\n","time = 15m, epoch 6, iter = 2600, loss = 1.194, 4s per 100 iters\n","time = 16m, epoch 6, iter = 2700, loss = 1.175, 4s per 100 iters\n","time = 16m, epoch 6, iter = 2800, loss = 1.177, 4s per 100 iters\n","time = 16m, epoch 6, iter = 2900, loss = 1.212, 5s per 100 iters\n","time = 16m, epoch 6, iter = 3000, loss = 1.201, 4s per 100 iters\n","time = 16m, epoch 6, iter = 3100, loss = 1.221, 4s per 100 iters\n","time = 16m, epoch 6, iter = 3200, loss = 1.186, 5s per 100 iters\n","time = 16m, epoch 6, iter = 3300, loss = 1.240, 4s per 100 iters\n","time = 16m, epoch 7, iter = 100, loss = 1.036, 9s per 100 iters\n","time = 16m, epoch 7, iter = 200, loss = 1.027, 4s per 100 iters\n","time = 16m, epoch 7, iter = 300, loss = 1.056, 4s per 100 iters\n","time = 16m, epoch 7, iter = 400, loss = 1.059, 4s per 100 iters\n","time = 16m, epoch 7, iter = 500, loss = 1.067, 4s per 100 iters\n","time = 17m, epoch 7, iter = 600, loss = 1.055, 4s per 100 iters\n","time = 17m, epoch 7, iter = 700, loss = 1.066, 4s per 100 iters\n","time = 17m, epoch 7, iter = 800, loss = 1.074, 4s per 100 iters\n","time = 17m, epoch 7, iter = 900, loss = 1.068, 5s per 100 iters\n","time = 17m, epoch 7, iter = 1000, loss = 1.086, 4s per 100 iters\n","time = 17m, epoch 7, iter = 1100, loss = 1.078, 4s per 100 iters\n","time = 17m, epoch 7, iter = 1200, loss = 1.088, 4s per 100 iters\n","time = 17m, epoch 7, iter = 1300, loss = 1.073, 4s per 100 iters\n","time = 17m, epoch 7, iter = 1400, loss = 1.089, 4s per 100 iters\n","time = 17m, epoch 7, iter = 1500, loss = 1.106, 4s per 100 iters\n","time = 17m, epoch 7, iter = 1600, loss = 1.094, 4s per 100 iters\n","time = 17m, epoch 7, iter = 1700, loss = 1.067, 4s per 100 iters\n","time = 18m, epoch 7, iter = 1800, loss = 1.097, 4s per 100 iters\n","time = 18m, epoch 7, iter = 1900, loss = 1.062, 5s per 100 iters\n","time = 18m, epoch 7, iter = 2000, loss = 1.081, 4s per 100 iters\n","time = 18m, epoch 7, iter = 2100, loss = 1.098, 4s per 100 iters\n","time = 18m, epoch 7, iter = 2200, loss = 1.097, 4s per 100 iters\n","time = 18m, epoch 7, iter = 2300, loss = 1.118, 4s per 100 iters\n","time = 18m, epoch 7, iter = 2400, loss = 1.114, 4s per 100 iters\n","time = 18m, epoch 7, iter = 2500, loss = 1.095, 4s per 100 iters\n","time = 18m, epoch 7, iter = 2600, loss = 1.074, 4s per 100 iters\n","time = 18m, epoch 7, iter = 2700, loss = 1.114, 4s per 100 iters\n","time = 18m, epoch 7, iter = 2800, loss = 1.113, 4s per 100 iters\n","time = 18m, epoch 7, iter = 2900, loss = 1.106, 4s per 100 iters\n","time = 19m, epoch 7, iter = 3000, loss = 1.117, 4s per 100 iters\n","time = 19m, epoch 7, iter = 3100, loss = 1.151, 4s per 100 iters\n","time = 19m, epoch 7, iter = 3200, loss = 1.121, 4s per 100 iters\n","time = 19m, epoch 7, iter = 3300, loss = 1.136, 4s per 100 iters\n","time = 19m, epoch 8, iter = 100, loss = 0.965, 9s per 100 iters\n","time = 19m, epoch 8, iter = 200, loss = 0.993, 4s per 100 iters\n","time = 19m, epoch 8, iter = 300, loss = 0.968, 4s per 100 iters\n","time = 19m, epoch 8, iter = 400, loss = 0.970, 4s per 100 iters\n","time = 19m, epoch 8, iter = 500, loss = 0.974, 4s per 100 iters\n","time = 19m, epoch 8, iter = 600, loss = 0.961, 4s per 100 iters\n","time = 19m, epoch 8, iter = 700, loss = 0.983, 4s per 100 iters\n","time = 20m, epoch 8, iter = 800, loss = 0.972, 4s per 100 iters\n","time = 20m, epoch 8, iter = 900, loss = 1.008, 4s per 100 iters\n","time = 20m, epoch 8, iter = 1000, loss = 0.982, 4s per 100 iters\n","time = 20m, epoch 8, iter = 1100, loss = 1.011, 4s per 100 iters\n","time = 20m, epoch 8, iter = 1200, loss = 0.978, 4s per 100 iters\n","time = 20m, epoch 8, iter = 1300, loss = 0.997, 4s per 100 iters\n","time = 20m, epoch 8, iter = 1400, loss = 1.001, 4s per 100 iters\n","time = 20m, epoch 8, iter = 1500, loss = 0.963, 4s per 100 iters\n","time = 20m, epoch 8, iter = 1600, loss = 1.020, 5s per 100 iters\n","time = 20m, epoch 8, iter = 1700, loss = 1.042, 4s per 100 iters\n","time = 20m, epoch 8, iter = 1800, loss = 1.014, 4s per 100 iters\n","time = 20m, epoch 8, iter = 1900, loss = 1.006, 4s per 100 iters\n","time = 20m, epoch 8, iter = 2000, loss = 1.020, 4s per 100 iters\n","time = 21m, epoch 8, iter = 2100, loss = 1.037, 4s per 100 iters\n","time = 21m, epoch 8, iter = 2200, loss = 1.020, 4s per 100 iters\n","time = 21m, epoch 8, iter = 2300, loss = 1.052, 4s per 100 iters\n","time = 21m, epoch 8, iter = 2400, loss = 1.056, 4s per 100 iters\n","time = 21m, epoch 8, iter = 2500, loss = 1.024, 4s per 100 iters\n","time = 21m, epoch 8, iter = 2600, loss = 1.033, 4s per 100 iters\n","time = 21m, epoch 8, iter = 2700, loss = 1.030, 4s per 100 iters\n","time = 21m, epoch 8, iter = 2800, loss = 1.033, 4s per 100 iters\n","time = 21m, epoch 8, iter = 2900, loss = 1.034, 4s per 100 iters\n","time = 21m, epoch 8, iter = 3000, loss = 1.027, 4s per 100 iters\n","time = 21m, epoch 8, iter = 3100, loss = 1.027, 4s per 100 iters\n","time = 21m, epoch 8, iter = 3200, loss = 1.051, 4s per 100 iters\n","time = 22m, epoch 8, iter = 3300, loss = 1.042, 4s per 100 iters\n","time = 22m, epoch 9, iter = 100, loss = 0.896, 9s per 100 iters\n","time = 22m, epoch 9, iter = 200, loss = 0.872, 4s per 100 iters\n","time = 22m, epoch 9, iter = 300, loss = 0.917, 4s per 100 iters\n","time = 22m, epoch 9, iter = 400, loss = 0.876, 4s per 100 iters\n","time = 22m, epoch 9, iter = 500, loss = 0.916, 5s per 100 iters\n","time = 22m, epoch 9, iter = 600, loss = 0.902, 4s per 100 iters\n","time = 22m, epoch 9, iter = 700, loss = 0.921, 4s per 100 iters\n","time = 22m, epoch 9, iter = 800, loss = 0.914, 4s per 100 iters\n","time = 22m, epoch 9, iter = 900, loss = 0.937, 4s per 100 iters\n","time = 22m, epoch 9, iter = 1000, loss = 0.944, 4s per 100 iters\n","time = 22m, epoch 9, iter = 1100, loss = 0.926, 4s per 100 iters\n","time = 23m, epoch 9, iter = 1200, loss = 0.927, 4s per 100 iters\n","time = 23m, epoch 9, iter = 1300, loss = 0.967, 4s per 100 iters\n","time = 23m, epoch 9, iter = 1400, loss = 0.946, 4s per 100 iters\n","time = 23m, epoch 9, iter = 1500, loss = 0.950, 4s per 100 iters\n","time = 23m, epoch 9, iter = 1600, loss = 0.947, 4s per 100 iters\n","time = 23m, epoch 9, iter = 1700, loss = 0.961, 4s per 100 iters\n","time = 23m, epoch 9, iter = 1800, loss = 0.958, 4s per 100 iters\n","time = 23m, epoch 9, iter = 1900, loss = 0.953, 4s per 100 iters\n","time = 23m, epoch 9, iter = 2000, loss = 0.943, 4s per 100 iters\n","time = 23m, epoch 9, iter = 2100, loss = 0.962, 4s per 100 iters\n","time = 23m, epoch 9, iter = 2200, loss = 0.946, 4s per 100 iters\n","time = 23m, epoch 9, iter = 2300, loss = 0.959, 4s per 100 iters\n","time = 24m, epoch 9, iter = 2400, loss = 0.970, 4s per 100 iters\n","time = 24m, epoch 9, iter = 2500, loss = 0.959, 4s per 100 iters\n","time = 24m, epoch 9, iter = 2600, loss = 0.990, 4s per 100 iters\n","time = 24m, epoch 9, iter = 2700, loss = 0.957, 4s per 100 iters\n","time = 24m, epoch 9, iter = 2800, loss = 0.971, 4s per 100 iters\n","time = 24m, epoch 9, iter = 2900, loss = 0.964, 4s per 100 iters\n","time = 24m, epoch 9, iter = 3000, loss = 0.969, 5s per 100 iters\n","time = 24m, epoch 9, iter = 3100, loss = 0.976, 4s per 100 iters\n","time = 24m, epoch 9, iter = 3200, loss = 0.954, 4s per 100 iters\n","time = 24m, epoch 9, iter = 3300, loss = 0.966, 4s per 100 iters\n","time = 24m, epoch 10, iter = 100, loss = 0.824, 9s per 100 iters\n","time = 24m, epoch 10, iter = 200, loss = 0.847, 4s per 100 iters\n","time = 25m, epoch 10, iter = 300, loss = 0.826, 4s per 100 iters\n","time = 25m, epoch 10, iter = 400, loss = 0.850, 4s per 100 iters\n","time = 25m, epoch 10, iter = 500, loss = 0.853, 4s per 100 iters\n","time = 25m, epoch 10, iter = 600, loss = 0.848, 4s per 100 iters\n","time = 25m, epoch 10, iter = 700, loss = 0.871, 4s per 100 iters\n","time = 25m, epoch 10, iter = 800, loss = 0.859, 4s per 100 iters\n","time = 25m, epoch 10, iter = 900, loss = 0.884, 4s per 100 iters\n","time = 25m, epoch 10, iter = 1000, loss = 0.889, 4s per 100 iters\n","time = 25m, epoch 10, iter = 1100, loss = 0.873, 4s per 100 iters\n","time = 25m, epoch 10, iter = 1200, loss = 0.894, 4s per 100 iters\n","time = 25m, epoch 10, iter = 1300, loss = 0.876, 4s per 100 iters\n","time = 25m, epoch 10, iter = 1400, loss = 0.903, 4s per 100 iters\n","time = 26m, epoch 10, iter = 1500, loss = 0.901, 4s per 100 iters\n","time = 26m, epoch 10, iter = 1600, loss = 0.873, 4s per 100 iters\n","time = 26m, epoch 10, iter = 1700, loss = 0.896, 4s per 100 iters\n","time = 26m, epoch 10, iter = 1800, loss = 0.902, 4s per 100 iters\n","time = 26m, epoch 10, iter = 1900, loss = 0.915, 4s per 100 iters\n","time = 26m, epoch 10, iter = 2000, loss = 0.907, 4s per 100 iters\n","time = 26m, epoch 10, iter = 2100, loss = 0.917, 4s per 100 iters\n","time = 26m, epoch 10, iter = 2200, loss = 0.912, 4s per 100 iters\n","time = 26m, epoch 10, iter = 2300, loss = 0.922, 4s per 100 iters\n","time = 26m, epoch 10, iter = 2400, loss = 0.894, 4s per 100 iters\n","time = 26m, epoch 10, iter = 2500, loss = 0.917, 4s per 100 iters\n","time = 26m, epoch 10, iter = 2600, loss = 0.902, 4s per 100 iters\n","time = 27m, epoch 10, iter = 2700, loss = 0.923, 4s per 100 iters\n","time = 27m, epoch 10, iter = 2800, loss = 0.889, 4s per 100 iters\n","time = 27m, epoch 10, iter = 2900, loss = 0.896, 4s per 100 iters\n","time = 27m, epoch 10, iter = 3000, loss = 0.908, 4s per 100 iters\n","time = 27m, epoch 10, iter = 3100, loss = 0.927, 4s per 100 iters\n","time = 27m, epoch 10, iter = 3200, loss = 0.923, 4s per 100 iters\n","time = 27m, epoch 10, iter = 3300, loss = 0.951, 4s per 100 iters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BiaAAFHrb-Fl","executionInfo":{"status":"ok","timestamp":1605835105374,"user_tz":180,"elapsed":1659013,"user":{"displayName":"Franz Mayr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRTnWg4ZNbNk4EJmZr8aEF2OJJSctajnNcVacgzQE=s64","userId":"12112266360872341577"}}},"source":["def translate(model, src, max_len=80):\n","  model.eval()\n","\n","  input_pad = EN_TEXT.vocab.stoi['<pad>']\n","\n","  src = tokenize_en(src)\n","  src = (torch.LongTensor([[EN_TEXT.vocab.stoi[tok] for tok in src]])).cuda()\n","\n","  src_mask = (src != input_pad).unsqueeze(-2).cuda()\n","  e_outputs = model.encoder(src, src_mask)\n","      \n","  outputs = torch.zeros(max_len).type_as(src.data)\n","  outputs[0] = torch.LongTensor([FR_TEXT.vocab.stoi['<sos>']])\n","\n","  for i in range(1, max_len):    \n","    trg_mask = torch.triu(torch.ones((1, i, i))).type(torch.uint8)\n","    trg_mask = ((trg_mask) == 0).cuda()\n","          \n","    out = model.out(model.decoder(outputs[:i].unsqueeze(0), e_outputs, src_mask, trg_mask))\n","    out = F.softmax(out, dim=-1)\n","    val, ix = out[:, -1].data.topk(1)\n","    \n","    outputs[i] = ix[0][0]\n","\n","    if ix[0][0] == FR_TEXT.vocab.stoi['<eos>']:\n","        break\n","\n","  return ' '.join([FR_TEXT.vocab.itos[ix] for ix in outputs[:i]])"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"FALTQeiJdXQQ","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1605457625622,"user_tz":180,"elapsed":2319509,"user":{"displayName":"Juan Olloniego","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFZMy1xYdrq8EuW2y-CLv6Eae8Tfe4Qp-uZpYfQQ=s64","userId":"13959738928832749591"}},"outputId":"1421a8be-25e0-4477-92aa-673d86bacb83"},"source":["translate(model, \"How are you ?\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<sos> Comment êtes - vous ?'"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"EbHnAGr1WGeO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ky-OfrkNWGhZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kL5UiQeaWGkS"},"source":[""],"execution_count":null,"outputs":[]}]}